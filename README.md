# Bigram Language Model (Part of LMM)

This project is focused on building a simple Bigram Language Model (LMM). The model predicts the next word in a sequence by using the frequency of word pairs (bigrams) from a given text corpus.

## Features

- **Bigram generation**: The model creates word pairs from a corpus and counts their occurrences.
- **Next-word prediction**: Given a word, the model predicts the most probable word to follow based on bigram probabilities.
- **Corpus processing**: The code handles basic text pre-processing, including tokenization and case normalization.

## Files

- **bigram.ipynb**: The core Jupyter notebook containing the implementation of the Bigram Language Model. This file includes data preprocessing, bigram generation, and prediction methods.
  
---

Let me know if you'd like to customize any part of this!
